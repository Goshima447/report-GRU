{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b9996-f4a3-4672-9065-749c79b46fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手順1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 指定フォルダ内のすべてのtxtファイルを取得\n",
    "txt_files = glob.glob(os.path.join(r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_txt_to_csv\", \"sms-call-internet-mi-*.txt\"))\n",
    "\n",
    "# 列名を定義\n",
    "columns = [\"CellID\", \"datetime\", \"countrycode\", \"smsin\", \"smsout\", \"callin\", \"callout\", \"internet\"]\n",
    "\n",
    "# 各txtファイルを処理してcsvに変換\n",
    "for txt_file_path in txt_files:\n",
    "    csv_file_path = txt_file_path.replace(\".txt\", \".csv\")\n",
    "    \n",
    "    # 既にcsvファイルが存在する場合はスキップ\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        dataset = pd.read_csv(txt_file_path, delimiter=\"\\t\", names=columns)\n",
    "        dataset.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Converted {os.path.basename(txt_file_path)} to {os.path.basename(csv_file_path)}\")\n",
    "    else:\n",
    "        print(f\"Skipping {os.path.basename(txt_file_path)}, already converted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbb967-e1d8-40b8-91d5-ec0a6f44ff52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 手順２ （Datasets_txt_to_csv内に、mi-hour-*, mi-minute-*を作成）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "##  csvファイルを処理してデータを整形\n",
    "def format_data(time_unit: str):\n",
    "    # 指定ディレクトリ内のcsvファイルを取得\n",
    "    csv_files = glob.glob(os.path.join(r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_txt_to_csv\", \"sms-call-internet-mi-*.csv\"))\n",
    "\n",
    "    # 列名を定義\n",
    "    columns = [\"datetime\", \"CellID\", \"countrycode\", \"smsin\", \"smsout\", \"callin\", \"callout\", \"internet\"]\n",
    "    columns_order = ['datetime', 'CellID', 'sms', 'call', 'internet']\n",
    "\n",
    "    # 各列の型変換を辞書に格納\n",
    "    conversion_dict = {\n",
    "        'datetime': 'datetime64[ns]',\n",
    "        'CellID': 'int16',\n",
    "        'smsin': 'float64',\n",
    "        'smsout': 'float64',\n",
    "        'callin': 'float64',\n",
    "        'callout': 'float64',\n",
    "        'internet': 'float64',\n",
    "    }\n",
    "\n",
    "    # 各csvファイルを処理して列順を変換（smsとcallをまとめる）\n",
    "    for csv_file_path in csv_files:\n",
    "        dataset = pd.read_csv(csv_file_path)\n",
    "        dataset = dataset[columns]\n",
    "        dataset['datetime'] = pd.to_datetime(dataset['datetime'], unit='ms')\n",
    "        dataset = dataset.sort_values(by=[\"CellID\", \"datetime\"]).reset_index(drop=True)\n",
    "\n",
    "        dataset.fillna(0, inplace=True)\n",
    "        dataset = dataset.astype(conversion_dict)\n",
    "        dataset['sms'] = dataset['smsin'] + dataset['smsout']\n",
    "        dataset['call'] = dataset['callin'] + dataset['callout']\n",
    "        dataset = dataset[columns_order]\n",
    "        dataset = dataset[['datetime', 'CellID', 'sms', 'call', 'internet']].groupby(['datetime', 'CellID'], as_index=False).sum()\n",
    "\n",
    "        if time_unit == 'minute':\n",
    "            output_file_path = os.path.join(os.path.dirname(csv_file_path), f\"mi-minute-{dataset['datetime'].max().strftime('%Y-%m-%d')}.csv\")\n",
    "        elif time_unit == 'hour':\n",
    "            dataset['datetime'] = dataset['datetime'].dt.floor('1H')\n",
    "            dataset = dataset.groupby(['datetime', 'CellID']).sum().reset_index()\n",
    "            output_file_path = os.path.join(os.path.dirname(csv_file_path), f\"mi-hour-{dataset['datetime'].max().strftime('%Y-%m-%d')}.csv\")\n",
    "        else:\n",
    "            raise ValueError(\"time_unit must be 'minute' or 'hour'\")\n",
    "        \n",
    "        dataset.to_csv(output_file_path, index=False)\n",
    "        print(f\"Processed file: {os.path.basename(csv_file_path)} -> {os.path.basename(output_file_path)}\")\n",
    "\n",
    "# 呼び出し例：\n",
    "format_data('minute')\n",
    "format_data('hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05eb4a4-a143-497c-bef4-8348a2058329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 手順３（Datasets_IDディレクトリ内に、指定した範囲のグリッドデータを出力）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import get_cellid_within_range\n",
    "\n",
    "def filter_and_save_data(time_unit):\n",
    "    # ファイルを取得\n",
    "    csv_files = glob.glob(os.path.join(r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_txt_to_csv\", f\"mi-{time_unit}*.csv\"))\n",
    "    \n",
    "    # 出力ディレクトリを設定\n",
    "    if time_unit == 'hour':\n",
    "        output_dir = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_ID\\hour\"\n",
    "    elif time_unit == 'minute':\n",
    "        output_dir = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_ID\\minute\"\n",
    "    else:\n",
    "        raise ValueError(\"time_unit must be 'minute' or 'hour'\")\n",
    "    \n",
    "    # ディレクトリが存在しない場合は作成\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 指定した範囲のIDを取得（中心となる'CellID', 一辺の長さ）\n",
    "    cells_in_range = get_cellid_within_range.get_cells_in_range(5161, 30)\n",
    "\n",
    "    # セルIDごとのデータを格納する辞書を初期化\n",
    "    cell_filtered_datasets = {cell_id: [] for cell_id in cells_in_range}\n",
    "\n",
    "    # 各csvファイルを処理\n",
    "    for csv_file_path in csv_files:\n",
    "        dataset = pd.read_csv(csv_file_path)\n",
    "        dataset['datetime'] = pd.to_datetime(dataset['datetime'])\n",
    "\n",
    "        # 各セルIDに対するデータをフィルタリング\n",
    "        for cell_id in cells_in_range:\n",
    "            cell_data = dataset[dataset['CellID'] == cell_id]\n",
    "            if not cell_data.empty:  # データがある場合のみ追加\n",
    "                cell_filtered_datasets[cell_id].append(cell_data)\n",
    "\n",
    "    # すべてのCSVファイルを処理した後にデータを保存\n",
    "    for cell_id, cell_data_list in cell_filtered_datasets.items():\n",
    "        if cell_data_list:  # データがある場合のみ処理\n",
    "            combined_cell_dataset = pd.concat(cell_data_list, ignore_index=True)\n",
    "            \n",
    "            # 出力ファイルパスを作成\n",
    "            cell_output_file_path = os.path.join(output_dir, f\"mi-ID-{cell_id}.csv\")\n",
    "            combined_cell_dataset.to_csv(cell_output_file_path, index=False)\n",
    "            \n",
    "            print(f\"cell_id {cell_id} のデータを保存しました: {cell_output_file_path}\")\n",
    "\n",
    "\n",
    "filter_and_save_data('hour')\n",
    "filter_and_save_data('minute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51fbc8-3f51-46b8-b1cd-2c7101cb8f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 手順４　（Dataset_ID内の欠損データの補完）\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def fill_missing_data(time_unit):\n",
    "    \n",
    "    # ディレクトリの設定\n",
    "    if time_unit == 'hour':\n",
    "        base_dir = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_ID\\hour\"\n",
    "    elif time_unit == 'minute':\n",
    "        base_dir = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_ID\\minute\"\n",
    "    else:\n",
    "        raise ValueError(\"time_unitは 'hour' または 'minute' のいずれかを指定してください。\")\n",
    "\n",
    "    # base_file_pathは固定のmi-ID-5161.csv\n",
    "    base_file_path = os.path.join(base_dir, \"mi-ID-5161.csv\")\n",
    "    \n",
    "    # base_file_pathの読み込み\n",
    "    base_time = pd.read_csv(base_file_path, parse_dates=['datetime'])\n",
    "\n",
    "    # mi-ID-*.csv形式のファイルを取得\n",
    "    target_files = glob.glob(os.path.join(base_dir, \"mi-ID-*.csv\"))\n",
    "\n",
    "    # mi-ID-5161.csvを除外（base_timeとして使うファイルは除外する）\n",
    "    target_files = [file for file in target_files if file != base_file_path]\n",
    "\n",
    "    # 各ターゲットファイルに対して処理を行う\n",
    "    for target_file_path in target_files:\n",
    "        print(f\"処理中: {target_file_path}\")\n",
    "        \n",
    "        # ターゲットファイルを読み込む\n",
    "        target = pd.read_csv(target_file_path, parse_dates=['datetime'])\n",
    "\n",
    "        # base_timeのdatetime列を基準にインデックスを作成\n",
    "        base_time_index = base_time['datetime']\n",
    "\n",
    "        # ファイル2をdatetime列でインデックス化し、基準のインデックスに再インデックス\n",
    "        target = target.set_index('datetime').reindex(base_time_index)\n",
    "\n",
    "        # 欠損値補完\n",
    "        # CellIDは同じ値を維持\n",
    "        target['CellID'] = target['CellID'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        # sms, call, internetは0で補完\n",
    "        target[['sms', 'call', 'internet']] = target[['sms', 'call', 'internet']].fillna(0)\n",
    "\n",
    "        # インデックスをリセットして元の形式に戻す\n",
    "        target = target.reset_index()\n",
    "\n",
    "        # 補完後のデータを元のファイルに上書き保存\n",
    "        target.to_csv(target_file_path, index=False)\n",
    "\n",
    "        # 結果の確認（先頭5行を表示）\n",
    "        print(target.head())\n",
    "        print(f\"補完後のデータを {target_file_path} に上書き保存しました。\\n\")\n",
    "\n",
    "# 使用例\n",
    "fill_missing_data('hour')  # 'hour'を指定した場合\n",
    "fill_missing_data('minute')  # 'minute'を指定した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc8fe8-ef01-422b-acc8-2cda169ec94e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 手順５（Datasets_hour, Datasets_minute内に、train_*, test_*を作成）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## 11月分の訓練データと12月の第1週分のテストデータを取得するコード\n",
    "def process_and_split_data(time_unit):\n",
    "    # time_unitに基づいてファイルパスを取得\n",
    "    if time_unit == 'minute':\n",
    "        file_paths = glob.glob(os.path.join(r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_ID\", \"minute\", \"mi-ID-*.csv\"))\n",
    "        output_train = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_minute\\train\"\n",
    "        output_test = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_minute\\test\"\n",
    "    elif time_unit == 'hour':\n",
    "        file_paths = glob.glob(os.path.join(r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_ID\", \"hour\", \"mi-ID-*.csv\"))\n",
    "        output_train = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_hour\\train\"\n",
    "        output_test = r\"C:\\Users\\goshima\\Documents\\卒業研究_AI\\Python\\Datasets\\Datasets_hour\\test\"\n",
    "    else:\n",
    "        print(f\"Invalid time_unit: {time_unit}. Use 'minute' or 'hour'.\")\n",
    "        return\n",
    "    \n",
    "    # 出力先ディレクトリが存在しない場合は作成\n",
    "    os.makedirs(output_train, exist_ok=True)\n",
    "    os.makedirs(output_test, exist_ok=True)\n",
    "\n",
    "    # 各ファイルに対して処理を実行\n",
    "    for file_path in file_paths:\n",
    "        dataset = pd.read_csv(file_path)\n",
    "        dataset['datetime'] = pd.to_datetime(dataset['datetime'])\n",
    "\n",
    "        # 10月と12月のデータを除外（11月のデータ）\n",
    "        train_dataset = dataset[(dataset['datetime'].dt.month != 10) & (dataset['datetime'].dt.month != 12)]\n",
    "\n",
    "        # 12/1 0:00:00 ~ 12/8 23:59:59 間のデータを取得\n",
    "        test_dataset = dataset[(dataset['datetime'] >= '2013-12-01') & (dataset['datetime'] < '2013-12-09')]\n",
    "\n",
    "        # 出力ファイル名を動的に生成\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        train_file = f\"train_{base_name}.csv\"\n",
    "        test_file = f\"test_{base_name}.csv\"\n",
    "\n",
    "        # ファイルパスにディレクトリを追加\n",
    "        train_file_path = os.path.join(output_train, train_file)\n",
    "        test_file_path = os.path.join(output_test, test_file)\n",
    "\n",
    "        # 結果を保存\n",
    "        train_dataset.to_csv(train_file_path, index=False)\n",
    "        test_dataset.to_csv(test_file_path, index=False)\n",
    "\n",
    "        print(f\"Processed file: {os.path.basename(file_path)} -> {train_file}, {test_file}\")\n",
    "\n",
    "# 関数の使用例\n",
    "process_and_split_data('hour')\n",
    "process_and_split_data('minute')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (local_GPU)",
   "language": "python",
   "name": "local_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
